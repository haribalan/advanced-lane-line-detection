{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply a threshold on the sobel magnitude\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag / scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw a mask on top of an image\n",
    "def add_binary_mask(img, m):\n",
    "    m2 = np.zeros_like(img)\n",
    "    m2[:, :, 0] = m*255\n",
    "    m2[:, :, 1] = m\n",
    "    m2[:, :, 2] = m\n",
    "    img = np.where(m2, m2, img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class for perspective transforms\n",
    "class PerspectiveTransformer():\n",
    "    def __init__(self, src, dist):\n",
    "        self.Mpersp = cv2.getPerspectiveTransform(src, dst)\n",
    "        self.Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        \n",
    "    # Apply perspective transform\n",
    "    def warp(self, img):\n",
    "        return cv2.warpPerspective(img, self.Mpersp, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Reverse perspective transform\n",
    "    def unwarp(self, img):\n",
    "        return cv2.warpPerspective(img, self.Minv, (img.shape[1], img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applies the HLS and sobel masks to the image\n",
    "def mask_image(img):\n",
    "    img = img.copy()\n",
    "    \n",
    "    # Apply a mask on HLS colour channels\n",
    "    # This selects pixels with higher than 100 saturation and lower than 100 hue\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    mask = np.zeros_like(hls[:, :, 0])\n",
    "    mask[(hls[:, :, 2] > 100) & (hls[:, :, 0] < 100)] = 1\n",
    "    \n",
    "    # Apply a sobel magnitude threshold\n",
    "    # I apply a more lenient mag_thresh to the upper part of the transformed image, as this part is blurrier\n",
    "    # and will therefore have smoother gradients.\n",
    "    # On the bottom half, this selects pixels with >10 sobel magnitude, and on the top half, \n",
    "    # selects pixels with >35 sobel magnitude\n",
    "    upper_mag = mag_thresh(img, 3, (10, 255))\n",
    "    lower_mag = mag_thresh(img, 3, (35, 255))\n",
    "    \n",
    "    mag_mask = np.zeros_like(lower_mag)\n",
    "    mag_mask[:int(mag_mask.shape[0]/2), :] = upper_mag[:int(mag_mask.shape[0]/2), :]\n",
    "    mag_mask[int(mag_mask.shape[0]/2):, :] = lower_mag[int(mag_mask.shape[0]/2):, :]\n",
    "    \n",
    "    # Use the bitwise OR mask of both masks for the final mask\n",
    "    final_mask = np.maximum(mag_mask, mask)\n",
    "\n",
    "    # Return the transformed mask\n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the peaks of the bottom half, for sliding window analysis\n",
    "def find_initial_peaks(final_mask, bottom_pct=0.5):\n",
    "    # bottom_pct: How much of the bottom to use for initial tracer placement\n",
    "    \n",
    "    shape = final_mask.shape\n",
    "    \n",
    "    bottom_sect = final_mask[-int(bottom_pct*shape[0]):, :]\n",
    "    \n",
    "    left_peak = bottom_sect[:, :int(0.5*shape[1])].sum(axis=0).argmax()\n",
    "    right_peak = bottom_sect[:, int(0.5*shape[1]):].sum(axis=0).argmax() + 0.5*shape[1]\n",
    "    \n",
    "    # Return x-position of the two peaks\n",
    "    return left_peak, right_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This applies the sliding window approach to find lane pixels, and then fits a polynomial to the found pixels.\n",
    "def sliding_window_poly(final_mask, left_peak, right_peak, num_chunks=10, leeway=80):\n",
    "    # num_chunks: Number of chunks to split sliding window into\n",
    "    # leeway: Number of pixels on each side horizontally to consider\n",
    "    \n",
    "    # Split the image vertically into chunks, for analysis.\n",
    "    chunks = []\n",
    "    assert final_mask.shape[0] % num_chunks == 0, 'Number of chunks must be a factor of vertical resolution!'\n",
    "    px = final_mask.shape[0] / num_chunks # Pixels per chunk\n",
    "    for i in range(num_chunks):\n",
    "        chunk = final_mask[i*px:(i+1)*px, :]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    # Reverse the order of the chunks, in order to work from the bottom up\n",
    "    chunks = chunks[::-1]\n",
    "    \n",
    "    # Loop over chunks, finding the lane centre within the leeway.\n",
    "    lefts = [left_peak]\n",
    "    rights = [right_peak]\n",
    "    \n",
    "    left_px, left_py, right_px, right_py = [], [], [], []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        offset = (num_chunks-i-1)*px\n",
    "        \n",
    "        last_left = int(lefts[-1])\n",
    "        last_right = int(rights[-1])\n",
    "        \n",
    "        # Only consider pixels within +-leeway of last chunk location\n",
    "        temp_left_chunk = chunk.copy()\n",
    "        temp_left_chunk[:, :last_left-leeway] = 0\n",
    "        temp_left_chunk[:, last_left+leeway:] = 0\n",
    "        \n",
    "        temp_right_chunk = chunk.copy()\n",
    "        temp_right_chunk[:, :last_right-leeway] = 0\n",
    "        temp_right_chunk[:, last_right+leeway:] = 0\n",
    "        \n",
    "        # Save the x, y pixel indexes for calculating the polynomial\n",
    "        left_px.append(temp_left_chunk.nonzero()[1])\n",
    "        left_py.append(temp_left_chunk.nonzero()[0] + offset)\n",
    "        \n",
    "        right_px.append(temp_right_chunk.nonzero()[1])\n",
    "        right_py.append(temp_right_chunk.nonzero()[0] + offset)\n",
    "    \n",
    "    # Create x and y indice arrays for both lines\n",
    "    left_px = np.concatenate(left_px)\n",
    "    left_py = np.concatenate(left_py)\n",
    "    right_px = np.concatenate(right_px)\n",
    "    right_py = np.concatenate(right_py)\n",
    "    \n",
    "    # Fit the polynomials!\n",
    "    l_poly = np.polyfit(left_py, left_px, 2)\n",
    "    r_poly = np.polyfit(right_py, right_px, 2)\n",
    "    \n",
    "    return l_poly, r_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the lane line curvature\n",
    "def get_curvature(poly, mask):\n",
    "    yscale = 30 / 720 # Real world metres per y pixel\n",
    "    xscale = 3.7 / 700 # Real world metres per x pixel\n",
    "    \n",
    "    # Convert polynomial to set of points for refitting\n",
    "    ploty = np.linspace(0, mask.shape[0]-1, mask.shape[0])\n",
    "    fitx = poly[0] * ploty ** 2 + poly[1] * ploty + poly[2]\n",
    "    \n",
    "    # Fit new polynomial\n",
    "    fit_cr = np.polyfit(ploty * yscale, fitx * xscale, 2)\n",
    "    \n",
    "    # Calculate curve radius\n",
    "    curverad = ((1 + (2 * fit_cr[0] * np.max(ploty) * yscale + fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * fit_cr[0])\n",
    "    return curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the polygons on the image\n",
    "def plot_poly_orig(fitl, fitr, orig):\n",
    "    # Draw lines from polynomials\n",
    "    ploty = np.linspace(0, orig.shape[0]-1, orig.shape[0])\n",
    "    fitl = fitl[0]*ploty**2 + fitl[1]*ploty + fitl[2]\n",
    "    fitr = fitr[0]*ploty**2 + fitr[1]*ploty + fitr[2]\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([fitl, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([fitr, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Create an overlay from the lane lines\n",
    "    overlay = np.zeros_like(orig).astype(np.uint8)\n",
    "    cv2.fillPoly(overlay, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Apply inverse transform to the overlay to plot it on the original road\n",
    "    overlay = transform.unwarp(overlay)\n",
    "    \n",
    "    # Add the overlay to the original unwarped image\n",
    "    result = cv2.addWeighted(orig, 1, overlay, 0.3, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the offset of the car and the base of the lane lines\n",
    "def find_offset(l_poly, r_poly):\n",
    "    lane_width = 3.7  # metres\n",
    "    h = 720  # height of image (index of image bottom)\n",
    "    w = 1280 # width of image\n",
    "    \n",
    "    # Find the bottom pixel of the lane lines\n",
    "    l_px = l_poly[0] * h ** 2 + l_poly[1] * h + l_poly[2]\n",
    "    r_px = r_poly[0] * h ** 2 + r_poly[1] * h + r_poly[2]\n",
    "    \n",
    "    # Find the number of pixels per real metre\n",
    "    scale = lane_width / np.abs(l_px - r_px)\n",
    "    \n",
    "    # Find the midpoint\n",
    "    midpoint = np.mean([l_px, r_px])\n",
    "    \n",
    "    # Find the offset from the centre of the frame, and then multiply by scale\n",
    "    offset = (w/2 - midpoint) * scale\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Buffer for retaining curvature and polygon information between frames\n",
    "last_rad = None\n",
    "last_l_poly = None\n",
    "last_r_poly = None\n",
    "\n",
    "# Function to apply to frames of video\n",
    "def process_frame(img):\n",
    "    global last_rad, last_l_poly, last_r_poly\n",
    "    \n",
    "    # Define weights for smoothing\n",
    "    rad_alpha = 0.05\n",
    "    poly_alpha = 0.2\n",
    "    \n",
    "    # Undistort the image using the camera calibration\n",
    "    img = calibration.undistort(img)\n",
    "    \n",
    "    # Keep the untransformed image for later\n",
    "    orig = img.copy()\n",
    "    \n",
    "    # Apply perspective transform to the image\n",
    "    img = transform.warp(img)\n",
    "    \n",
    "    # Apply the HLS/Sobel mask to detect lane pixels\n",
    "    mask = mask_image(img)\n",
    "    \n",
    "    # Find initial histogram peaks\n",
    "    left_peak, right_peak = find_initial_peaks(mask)\n",
    "    \n",
    "    # Get the sliding window polynomials for each line line\n",
    "    l_poly, r_poly = sliding_window_poly(mask, left_peak, right_peak, leeway=80)\n",
    "    \n",
    "    # Update polynomials using weighted average with last frame\n",
    "    if last_l_poly is None:\n",
    "        # If first frame, initialise buffer\n",
    "        last_l_poly = l_poly\n",
    "        last_r_poly = r_poly\n",
    "    else:\n",
    "        # Otherwise, update buffer\n",
    "        l_poly = (1 - poly_alpha) * last_l_poly + poly_alpha * l_poly\n",
    "        r_poly = (1 - poly_alpha) * last_r_poly + poly_alpha * r_poly\n",
    "        last_l_poly = l_poly\n",
    "        last_r_poly = r_poly\n",
    "        \n",
    "    # Calculate the lane curvature radius\n",
    "    l_rad = get_curvature(l_poly, mask)\n",
    "    r_rad = get_curvature(r_poly, mask)\n",
    "    \n",
    "    # Get mean of curvatures\n",
    "    rad = np.mean([l_rad, r_rad])\n",
    "    \n",
    "    # Update curvature using weighted average with last frame\n",
    "    if last_rad is None:\n",
    "        last_rad = rad\n",
    "    else:\n",
    "        last_rad = (1 - rad_alpha) * last_rad + rad_alpha * rad\n",
    "        \n",
    "    # Create image\n",
    "    final = plot_poly_orig(l_poly, r_poly, orig)\n",
    "        \n",
    "    # Write radius on image\n",
    "    cv2.putText(final, 'Lane Radius: {}m'.format(int(last_rad)), (10, 50), cv2.FONT_HERSHEY_DUPLEX, 1.5, 255)\n",
    "    \n",
    "    # Write lane offset on image\n",
    "    offset = find_offset(l_poly, r_poly)\n",
    "    cv2.putText(final, 'Lane Offset: {}m'.format(round(offset, 4)), (10, 100), cv2.FONT_HERSHEY_DUPLEX, 1.5, 255)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CameraCalibration] Image 0 skipped during calibration as chessboard is not fully visible\n",
      "[CameraCalibration] Image 14 skipped during calibration as chessboard is not fully visible\n",
      "[CameraCalibration] Image 15 skipped during calibration as chessboard is not fully visible\n"
     ]
    }
   ],
   "source": [
    "# Initialise the camera calibration, so it can be applied to future images\n",
    "from calibration import CameraCalibration\n",
    "calib_imgs = [mpimg.imread(f) for f in sorted(glob.glob('./camera_cal/*.jpg'))]\n",
    "calibration = CameraCalibration(calib_imgs, 9, 6)\n",
    "\n",
    "src = np.array([[585, 460], [203, 720], [1127, 720], [695, 460]]).astype(np.float32)\n",
    "dst = np.array([[320, 0], [320, 720], [960, 720], [960, 0]]).astype(np.float32)\n",
    "\n",
    "# Create transformer object, this means that the transformer matrix only needs to be computed once\n",
    "transform = PerspectiveTransformer(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video out11.mp4\n",
      "[MoviePy] Writing video out11.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 485/485 [01:03<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: out11.mp4 \n",
      "\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "white_output = 'out11.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c670894d1e54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
